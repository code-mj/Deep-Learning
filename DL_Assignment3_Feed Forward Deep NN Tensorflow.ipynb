{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the political party from the tweet text and the handle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data description\n",
    "This dataset has three columns - label (party name), twitter handle, tweet text\n",
    "\n",
    "\n",
    "#### Problem Description:\n",
    "\n",
    "Design a feed forward deep neural network to predict the political party using the pytorch or tensorflow. \n",
    "Build two models\n",
    "\n",
    "1. Without using the handle\n",
    "\n",
    "2. Using the handle\n",
    "\n",
    "\n",
    "#### Deliverables\n",
    "\n",
    "- Report the performance on the test set.\n",
    "\n",
    "- Try multiple models and with different hyperparameters. Present the results of each model on the test set. No need to create a dev set.\n",
    "\n",
    "- Experiment with:\n",
    "    -L2 and dropout regularization techniques\n",
    "    -SGD, RMSProp and Adamp optimization techniques\n",
    "\n",
    "\n",
    "\n",
    "- Creating a fixed-sized vocabulary: Give a unique id to each word in your selected vocabulary and use it as the input to the network\n",
    "\n",
    "    - Option 1: Feedforward networks can only handle fixed-sized inputs. You can choose to have a fixed-sized K words from the tweet text (e.g. the first K word, randomly selected K word etc.). K can be a hyperparameter. \n",
    "\n",
    "    - Option 2: you can choose top N (e.g. N=1000) frequent words from the dataset and use an N-sized input layer. If a word is present in a tweet, pass the id, 0 otherwise\n",
    "    \n",
    "    -  Clearly state your design choices and assumptions. Think about the pros and cons of each option.\n",
    "\n",
    " \n",
    "\n",
    "<b> Tabulate your results, either at the end of the code file or in the text box on the submission page. The final result should have:</b>\n",
    "\n",
    "1. Experiment description\n",
    "\n",
    "2. Hyperparameter used and their values\n",
    "\n",
    "3. Performance on the test set\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\mansi\\anaconda3\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.22.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.56.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.13.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\mansi\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "#You can install TensorFlow and Keras with pip.\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Check TensorFlow version\n",
    "print(\"TensorFlow version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test datasets\n",
    "train_data = pd.read_csv(\"C:\\\\Users\\\\mansi\\\\Downloads\\\\train.csv\")\n",
    "test_data = pd.read_csv(\"C:\\\\Users\\\\mansi\\\\Downloads\\\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle NaN values in the \"Tweet\" column\n",
    "train_data['Tweet'].fillna('', inplace=True)\n",
    "test_data['Tweet'].fillna('', inplace=True)\n",
    "\n",
    "# Preprocess tweet text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_data['Tweet'])\n",
    "X_train = tokenizer.texts_to_sequences(train_data['Tweet'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Tweet'])\n",
    "\n",
    "# Specify the number of words (K) to select from each tweet\n",
    "K = 20 # Option 1\n",
    "X_train = [seq[:K] for seq in X_train]\n",
    "X_test = [seq[:K] for seq in X_test]\n",
    "\n",
    "# Pad sequences to a fixed length\n",
    "max_seq_length = K \n",
    "X_train = pad_sequences(X_train, maxlen=max_seq_length)\n",
    "X_test = pad_sequences(X_test, maxlen=max_seq_length)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(train_data['Party'])\n",
    "y_test = label_encoder.transform(test_data['Party'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code uses Option 1 to create fixed-size vocabulary because it is simpler to implement and it can be used to capture sequential nature of tweet text. \n",
    "\n",
    "Although this option may not be good for capturing all of the important information.\n",
    "For capturing all the important information, option 2 is recommended. Option 2 is less sensitive to the order of the words in the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and compile the model without handles using ADAM optimizer\n",
    "def build_model_without_handles_adam():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_seq_length))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))  # Adding dropout for regularization\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model_without_handles_adam = build_model_without_handles_adam()\n",
    "model_without_handles_adam.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Using SGD optimizer\n",
    "def build_model_without_handles_sgd():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_seq_length))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model_without_handles_sgd = build_model_without_handles_sgd()\n",
    "model_without_handles_sgd.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Using RMSProp optimizer\n",
    "def build_model_without_handles_rmsprop():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_seq_length))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model_without_handles_rmsprop = build_model_without_handles_rmsprop()\n",
    "model_without_handles_rmsprop.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models with different hyperparameters\n",
    "def train_model(model, X_train, y_train, epochs=5, batch_size=64):\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 232s 203ms/step - loss: 0.5125 - accuracy: 0.7285\n",
      "Epoch 2/10\n",
      "1137/1137 [==============================] - 200s 176ms/step - loss: 0.2012 - accuracy: 0.9177\n",
      "Epoch 3/10\n",
      "1137/1137 [==============================] - 197s 174ms/step - loss: 0.0509 - accuracy: 0.9819\n",
      "Epoch 4/10\n",
      "1137/1137 [==============================] - 198s 174ms/step - loss: 0.0215 - accuracy: 0.9929\n",
      "Epoch 5/10\n",
      "1137/1137 [==============================] - 267s 235ms/step - loss: 0.0164 - accuracy: 0.9942\n",
      "Epoch 6/10\n",
      "1137/1137 [==============================] - 266s 234ms/step - loss: 0.0137 - accuracy: 0.9948\n",
      "Epoch 7/10\n",
      "1137/1137 [==============================] - 244s 214ms/step - loss: 0.0117 - accuracy: 0.9955\n",
      "Epoch 8/10\n",
      "1137/1137 [==============================] - 327s 287ms/step - loss: 0.0096 - accuracy: 0.9962\n",
      "Epoch 9/10\n",
      "1137/1137 [==============================] - 214s 189ms/step - loss: 0.0066 - accuracy: 0.9972\n",
      "Epoch 10/10\n",
      "1137/1137 [==============================] - 207s 182ms/step - loss: 0.0077 - accuracy: 0.9972\n",
      "Epoch 1/10\n",
      "1137/1137 [==============================] - 85s 74ms/step - loss: 0.7612 - accuracy: 0.5103\n",
      "Epoch 2/10\n",
      "1137/1137 [==============================] - 84s 74ms/step - loss: 0.6986 - accuracy: 0.5192\n",
      "Epoch 3/10\n",
      "1137/1137 [==============================] - 170s 149ms/step - loss: 0.6934 - accuracy: 0.5283\n",
      "Epoch 4/10\n",
      "1137/1137 [==============================] - 101s 89ms/step - loss: 0.6918 - accuracy: 0.5300\n",
      "Epoch 5/10\n",
      "1137/1137 [==============================] - 103s 91ms/step - loss: 0.6903 - accuracy: 0.5360\n",
      "Epoch 6/10\n",
      "1137/1137 [==============================] - 93s 82ms/step - loss: 0.6891 - accuracy: 0.5401\n",
      "Epoch 7/10\n",
      "1137/1137 [==============================] - 115s 101ms/step - loss: 0.6878 - accuracy: 0.5452\n",
      "Epoch 8/10\n",
      "1137/1137 [==============================] - 114s 100ms/step - loss: 0.6860 - accuracy: 0.5517\n",
      "Epoch 9/10\n",
      "1137/1137 [==============================] - 108s 95ms/step - loss: 0.6831 - accuracy: 0.5634\n",
      "Epoch 10/10\n",
      "1137/1137 [==============================] - 100s 88ms/step - loss: 0.6795 - accuracy: 0.5717\n",
      "Epoch 1/10\n",
      "1137/1137 [==============================] - 82s 72ms/step - loss: 0.5507 - accuracy: 0.7014\n",
      "Epoch 2/10\n",
      "1137/1137 [==============================] - 83s 73ms/step - loss: 0.3662 - accuracy: 0.8341\n",
      "Epoch 3/10\n",
      "1137/1137 [==============================] - 81s 71ms/step - loss: 0.2170 - accuracy: 0.9144\n",
      "Epoch 4/10\n",
      "1137/1137 [==============================] - 82s 72ms/step - loss: 0.1085 - accuracy: 0.9607\n",
      "Epoch 5/10\n",
      "1137/1137 [==============================] - 83s 73ms/step - loss: 0.0524 - accuracy: 0.9816\n",
      "Epoch 6/10\n",
      "1137/1137 [==============================] - 91s 80ms/step - loss: 0.0270 - accuracy: 0.9912\n",
      "Epoch 7/10\n",
      "1137/1137 [==============================] - 78s 68ms/step - loss: 0.0174 - accuracy: 0.9945\n",
      "Epoch 8/10\n",
      "1137/1137 [==============================] - 68s 59ms/step - loss: 0.0115 - accuracy: 0.9965\n",
      "Epoch 9/10\n",
      "1137/1137 [==============================] - 70s 62ms/step - loss: 0.0085 - accuracy: 0.9974\n",
      "Epoch 10/10\n",
      "1137/1137 [==============================] - 68s 60ms/step - loss: 0.0078 - accuracy: 0.9975\n"
     ]
    }
   ],
   "source": [
    "# Experiment models with different optimizers\n",
    "train_model(model_without_handles_adam, X_train, y_train, epochs=10, batch_size=64)\n",
    "train_model(model_without_handles_sgd, X_train, y_train, epochs=10, batch_size=64)\n",
    "train_model(model_without_handles_rmsprop, X_train, y_train, epochs=10, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 1s 1ms/step\n",
      "429/429 [==============================] - 1s 1ms/step\n",
      "429/429 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models on the test set\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    return accuracy\n",
    "\n",
    "accuracy_without_handles_adam = evaluate_model(model_without_handles_adam, X_test, y_test)\n",
    "accuracy_without_handles_sgd = evaluate_model(model_without_handles_sgd, X_test, y_test)\n",
    "accuracy_without_handles_rmsprop = evaluate_model(model_without_handles_rmsprop, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without Handles (Adam): 0.7550633833600466\n",
      "Accuracy without Handles (SGD): 0.5801398805187236\n",
      "Accuracy without Handles (RMSProp): 0.7401282238088299\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy without Handles (Adam):\", accuracy_without_handles_adam)\n",
    "print(\"Accuracy without Handles (SGD):\", accuracy_without_handles_sgd)\n",
    "print(\"Accuracy without Handles (RMSProp):\", accuracy_without_handles_rmsprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With \"Handle\" column\n",
    "train_data['Tweet'].fillna('', inplace=True)\n",
    "train_data['Handle'].fillna('', inplace=True)\n",
    "test_data['Tweet'].fillna('', inplace=True)\n",
    "test_data['Handle'].fillna('', inplace=True)\n",
    "\n",
    "train_data['Text'] = train_data['Handle'] + ' ' + train_data['Tweet']\n",
    "test_data['Text'] = test_data['Handle'] + ' ' + test_data['Tweet']\n",
    "\n",
    "# Preprocess tweet text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_data['Text'])\n",
    "X_train = tokenizer.texts_to_sequences(train_data['Text'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Text'])\n",
    "\n",
    "K = 20  # Option 1\n",
    "X_train = [seq[:K] for seq in X_train]\n",
    "X_test = [seq[:K] for seq in X_test]\n",
    "\n",
    "# Pad sequences to a fixed length\n",
    "max_seq_length = K\n",
    "X_train = pad_sequences(X_train, maxlen=max_seq_length)\n",
    "X_test = pad_sequences(X_test, maxlen=max_seq_length)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(train_data['Party'])\n",
    "y_test = label_encoder.transform(test_data['Party'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and compile the model with handles using ADAM optimizer\n",
    "def build_model_with_handles_adam():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_seq_length))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))  # Adding dropout for regularization\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model_with_handles_adam = build_model_with_handles_adam()\n",
    "custom_learning_rate = 0.15\n",
    "adam_optimizer = Adam(learning_rate=custom_learning_rate)\n",
    "model_with_handles_adam.compile(loss='sparse_categorical_crossentropy', optimizer=adam_optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Using SGD optimizer\n",
    "def build_model_with_handles_sgd():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_seq_length))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model_with_handles_sgd = build_model_with_handles_sgd()\n",
    "custom_learning_rate = 0.01\n",
    "sgd_optimizer = SGD(learning_rate=custom_learning_rate)\n",
    "model_with_handles_sgd.compile(loss='sparse_categorical_crossentropy', optimizer=sgd_optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Using RMSProp optimizer\n",
    "def build_model_with_handles_rmsprop():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_seq_length))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.75))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model_with_handles_rmsprop = build_model_with_handles_rmsprop()\n",
    "custom_learning_rate = 0.22\n",
    "rmsprop_optimizer = RMSprop(learning_rate=custom_learning_rate)\n",
    "model_with_handles_rmsprop.compile(loss='sparse_categorical_crossentropy', optimizer=rmsprop_optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1137/1137 [==============================] - 186s 163ms/step - loss: 3.9773 - accuracy: 0.5007\n",
      "Epoch 2/10\n",
      "1137/1137 [==============================] - 182s 160ms/step - loss: 11.1383 - accuracy: 0.5046\n",
      "Epoch 3/10\n",
      "1137/1137 [==============================] - 180s 158ms/step - loss: 1.4945 - accuracy: 0.5027\n",
      "Epoch 4/10\n",
      "1137/1137 [==============================] - 181s 159ms/step - loss: 20.1701 - accuracy: 0.5053\n",
      "Epoch 5/10\n",
      "1137/1137 [==============================] - 182s 160ms/step - loss: 18.2803 - accuracy: 0.5036\n",
      "Epoch 6/10\n",
      "1137/1137 [==============================] - 181s 159ms/step - loss: 45.0639 - accuracy: 0.5055\n",
      "Epoch 7/10\n",
      "1137/1137 [==============================] - 182s 160ms/step - loss: 5.1741 - accuracy: 0.5047\n",
      "Epoch 8/10\n",
      "1137/1137 [==============================] - 198s 174ms/step - loss: 2.4329 - accuracy: 0.5009\n",
      "Epoch 9/10\n",
      "1137/1137 [==============================] - 226s 199ms/step - loss: 7.3606 - accuracy: 0.5044\n",
      "Epoch 10/10\n",
      "1137/1137 [==============================] - 183s 161ms/step - loss: 3.4524 - accuracy: 0.5090\n",
      "Epoch 1/5\n",
      "1137/1137 [==============================] - 78s 68ms/step - loss: 0.7626 - accuracy: 0.5205\n",
      "Epoch 2/5\n",
      "1137/1137 [==============================] - 75s 66ms/step - loss: 0.6943 - accuracy: 0.5421\n",
      "Epoch 3/5\n",
      "1137/1137 [==============================] - 78s 68ms/step - loss: 0.6856 - accuracy: 0.5738\n",
      "Epoch 4/5\n",
      "1137/1137 [==============================] - 78s 68ms/step - loss: 0.6675 - accuracy: 0.6420\n",
      "Epoch 5/5\n",
      "1137/1137 [==============================] - 75s 66ms/step - loss: 0.5607 - accuracy: 0.7985\n",
      "Epoch 1/12\n",
      "1137/1137 [==============================] - 69s 60ms/step - loss: 13.3948 - accuracy: 0.5032\n",
      "Epoch 2/12\n",
      "1137/1137 [==============================] - 71s 63ms/step - loss: 2.0459 - accuracy: 0.5001\n",
      "Epoch 3/12\n",
      "1137/1137 [==============================] - 71s 63ms/step - loss: 2.5317 - accuracy: 0.5054\n",
      "Epoch 4/12\n",
      "1137/1137 [==============================] - 71s 62ms/step - loss: 1.1561 - accuracy: 0.4981\n",
      "Epoch 5/12\n",
      "1137/1137 [==============================] - 73s 64ms/step - loss: 0.8043 - accuracy: 0.5044\n",
      "Epoch 6/12\n",
      "1137/1137 [==============================] - 83s 73ms/step - loss: 0.8400 - accuracy: 0.5010\n",
      "Epoch 7/12\n",
      "1137/1137 [==============================] - 72s 64ms/step - loss: 0.7170 - accuracy: 0.5019\n",
      "Epoch 8/12\n",
      "1137/1137 [==============================] - 94s 82ms/step - loss: 0.8478 - accuracy: 0.5003\n",
      "Epoch 9/12\n",
      "1137/1137 [==============================] - 88s 78ms/step - loss: 0.8110 - accuracy: 0.5019\n",
      "Epoch 10/12\n",
      "1137/1137 [==============================] - 103s 90ms/step - loss: 1.0455 - accuracy: 0.5005\n",
      "Epoch 11/12\n",
      "1137/1137 [==============================] - 87s 76ms/step - loss: 1.0421 - accuracy: 0.5018\n",
      "Epoch 12/12\n",
      "1137/1137 [==============================] - 85s 75ms/step - loss: 0.8725 - accuracy: 0.5040\n"
     ]
    }
   ],
   "source": [
    "# Train models with different optimizers\n",
    "train_model(model_with_handles_adam, X_train, y_train, epochs=10, batch_size=64)\n",
    "train_model(model_with_handles_sgd, X_train, y_train, epochs=5, batch_size=64)\n",
    "train_model(model_with_handles_rmsprop, X_train, y_train, epochs=12, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 1s 1ms/step\n",
      "429/429 [==============================] - 1s 1ms/step\n",
      "429/429 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models on the test set\n",
    "accuracy_with_handles_adam = evaluate_model(model_with_handles_adam, X_test, y_test)\n",
    "accuracy_with_handles_sgd = evaluate_model(model_with_handles_sgd, X_test, y_test)\n",
    "accuracy_with_handles_rmsprop = evaluate_model(model_with_handles_rmsprop, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Handles (Adam): 0.4939530817426781\n",
      "Accuracy with Handles (SGD): 0.8902083636893486\n",
      "Accuracy with Handles (RMSProp): 0.4939530817426781\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy with Handles (Adam):\", accuracy_with_handles_adam)\n",
    "print(\"Accuracy with Handles (SGD):\", accuracy_with_handles_sgd)\n",
    "print(\"Accuracy with Handles (RMSProp):\", accuracy_with_handles_rmsprop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabulate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Experimental Description  \\\n",
      "0     Feed forward network without Handles (Adam)   \n",
      "1        Feed forward network with Handles (Adam)   \n",
      "2      Feed forward network without Handles (SGD)   \n",
      "3         Feed forward network with Handles (SGD)   \n",
      "4  Feed forward network without Handles (RMSProp)   \n",
      "5     Feed forward network with Handles (RMSProp)   \n",
      "\n",
      "                                     Hyperparameters  \\\n",
      "0  K = 20, Learning rate = 0.001, Dropout probabl...   \n",
      "1  K = 20, Learning rate = 0.15, Dropout probabli...   \n",
      "2  K = 20, Learning rate = 0.001, Dropout probabl...   \n",
      "3  K = 20, Learning rate = 0.01, Dropout probabli...   \n",
      "4  K = 20, Learning rate = 0.001, Dropout probabl...   \n",
      "5  K = 20, Learning rate = 0.22, Dropout probabli...   \n",
      "\n",
      "   Performance on the Test Set  \n",
      "0                     0.755063  \n",
      "1                     0.493953  \n",
      "2                     0.580140  \n",
      "3                     0.890208  \n",
      "4                     0.740128  \n",
      "5                     0.493953  \n"
     ]
    }
   ],
   "source": [
    "result = {\n",
    "    'Experimental Description': ['Feed forward network without Handles (Adam)', 'Feed forward network with Handles (Adam)', 'Feed forward network without Handles (SGD)',\n",
    "                                 'Feed forward network with Handles (SGD)', 'Feed forward network without Handles (RMSProp)', 'Feed forward network with Handles (RMSProp)'],\n",
    "    'Hyperparameters': [\"K = 20, Learning rate = 0.001, Dropout probablity = 0.5, epoch = 10\",\n",
    "                        \"K = 20, Learning rate = 0.15, Dropout probablity = 0.5, epoch = 10\",\n",
    "                        \"K = 20, Learning rate = 0.001, Dropout probablity = 0.5, epoch = 10\",\n",
    "                        \"K = 20, Learning rate = 0.01, Dropout probablity = 0.2, epoch = 5\",\n",
    "                        \"K = 20, Learning rate = 0.001, Dropout probablity = 0.5, epoch = 10\",\n",
    "                        \"K = 20, Learning rate = 0.22, Dropout probablity = 0.75, epoch = 12\"],\n",
    "    'Performance on the Test Set': [0.755063383, 0.493953082, 0.580139881, 0.890208364, 0.740128224, 0.493953082]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(result)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
